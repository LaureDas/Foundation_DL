{"cells":[{"cell_type":"markdown","metadata":{"id":"JNx-DlWhUojN"},"source":["# Deep Learning Course: Lab Exercises"]},{"cell_type":"markdown","metadata":{"id":"sfmNFn5pUojN"},"source":["In this lab exercise you will become familiar with the PyTorch library in order to solve deep learning problems. The goals of this assignments are as follows:\n","\n","- familiarize with PyTorch Tensors\n","\n","- understand how feedforward backpropagation works in neural networks\n"]},{"cell_type":"markdown","metadata":{"id":"h4j7Gf5LUojO"},"source":["# Setup"]},{"cell_type":"markdown","metadata":{"id":"efuanY_UUojO"},"source":["For this exercise the only thing you need is this notebook."]},{"cell_type":"markdown","metadata":{"id":"pZumXYTYUojO"},"source":["# Note"]},{"cell_type":"markdown","metadata":{"id":"P-6WBdq3UojO"},"source":["Apart from the Questions, there are instruction comments throughout the notebook as well as comments inside the code cells beginning with two hashtags (##). In addition, there are #**START CODE  /  #**END CODE comments indicating the start and end of your code sections. Pay attention not to delete these comments."]},{"cell_type":"markdown","metadata":{"id":"_YQ2FNeqUojP"},"source":["# Questions"]},{"cell_type":"markdown","metadata":{"id":"-2LYwZGKUojP"},"source":["# Q1 - PyTorch Tensors"]},{"cell_type":"markdown","metadata":{"id":"aOus3aXGUojP"},"source":["a) Get familiar with PyTorch Tensors and construct different types of them."]},{"cell_type":"code","execution_count":1,"metadata":{"id":"g95S8R61UojP"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[ 0.0000e+00, -2.0000e+00,  0.0000e+00],\n","        [-2.0000e+00,  7.8534e+34,  4.7418e+30],\n","        [ 5.9663e-02,  7.0374e+22, -4.5390e-01],\n","        [ 4.5747e-41, -4.5391e-01,  4.5747e-41],\n","        [ 0.0000e+00, -2.0000e+00,  0.0000e+00]])\n"]}],"source":["import torch\n","\n","##Construct a 5x3 matrix, uninitialized\n","# *****START CODE\n","x = torch.empty(5,3)\n","# *****END CODE\n","print(x)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MkCzwPzxUojQ"},"outputs":[],"source":["##Construct a randomly initialized matrix from a normal distribution\n","# *****START CODE\n","\n","x = \n","# *****END CODE\n","print(x)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pe99pXJHUojQ"},"outputs":[],"source":["##Construct a matrix filled with zeros and of dtype int64\n","# *****START CODE\n","\n","x = \n","# *****END CODE\n","print(x)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"R43-VxQ6UojQ"},"outputs":[],"source":["##Construct a tensor directly from data\n","# *****START CODE\n","\n","x = \n","# *****END CODE\n","print(x)"]},{"cell_type":"markdown","metadata":{"id":"UORgptIYUojR"},"source":["#Q2 Backpropagation from scratch\n","\n","- Create random input and output PyTorch tensors and train a simple network from scratch.\n","\n","  Warning: You should NOT use any forward/backward commands from PyTorch             library."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QtrAESF-UojR"},"outputs":[],"source":["import torch.nn.functional as F\n","\n","## N is batch size; D_in is input dimension\n","## H is hidden dimenion; D_out is output dimension\n","\n","N, D_in, H, D_out = 64, 1000, 100, 10\n","\n","## Create random input (x) and output (y) data\n","# *****START CODE\n","x = \n","y = \n","print('x', x.shape)\n","print('y', y.shape)\n","# *****END CODE\n","\n","    "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zofILGJ3VCBz"},"outputs":[],"source":["##Randomly initialize weights from a normal distribution, skipping bias\n","##Hint: You need 2 weight tensors; one for the raw input tensor (x) and one for the hidden dimension\n","# *****START CODE\n","w1 = \n","w2 = \n","# *****END CODE\n","print('w1', w1.shape)\n","print('w2', w2.shape)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9sQA5kvXVLge"},"outputs":[],"source":["##define the learning rate\n","learning_rate = 1e-6\n"]},{"cell_type":"markdown","metadata":{"id":"9xgDIJGcVfnb"},"source":["First, implement the forward pass. Try to compute the predicted y_pred value."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OlQ0tMGsVQrz"},"outputs":[],"source":["## Calculate the output of the hidden dimension\n","## Hint: make use of torch.matmul()\n","# *****START CODE\n","import torch.nn.functional as F\n","h =                 # output of the hidden dimension \n","# *****END CODE  \n","print('h', h.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8NbtF0QtWA25"},"outputs":[],"source":["## Pass the output of the hidden dimension to the ReLU activation function\n","# *****START CODE\n","h_relu =            # output of the ReLU function\n","# *****END CODE  "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xAMaSc7JWA-E"},"outputs":[],"source":["## Calculate the final output of the network\n","# *****START CODE\n","y_pred =            # final output of the network\n","# *****END CODE\n","print('y_pred', y_pred.shape)"]},{"cell_type":"markdown","metadata":{"id":"6xHdnKovWvIk"},"source":["Calculate the loss."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"usvfBgnWVQ4T"},"outputs":[],"source":["## Compute loss\n","loss = ((y_pred - y) ** 2).mean()\n","print(loss)"]},{"cell_type":"markdown","metadata":{"id":"QklmgLMnW1k_"},"source":["Now, implement the backward pass.\n","You need to minimize the loss with respect to each weight using the chain rule of differentiation."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rOlsl-15W35z"},"outputs":[],"source":["## Compute the gradient of w2 with respect to the loss\n","# *****START CODE\n","\n","\n","# *****END CODE\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PVWLJdcwXF_C"},"outputs":[],"source":["## Compute the gradient of w1 with respect to the loss (consider the derivative of ReLU equal to 1)\n","# *****START CODE\n","\n","\n","# *****END CODE"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cdZx29tlXNUx"},"outputs":[],"source":["## Update weights\n","# *****START CODE\n","\n","\n","# *****END CODE"]},{"cell_type":"markdown","metadata":{"id":"2DWDA8CZXU5p"},"source":["Repeat the above process for a number of epochs and notice how the value of the loss changes."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jWbfq-36XkRN"},"outputs":[],"source":["##specify the number of epochs\n","# *****START CODE\n","epochs =\n","# *****END CODE\n","\n","for t in range(epochs):\n","  # *****START CODE\n","\n","\n","\n","\n","  # *****END CODE\n","\n","\n"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"DL_LAB_1.ipynb","provenance":[]},"interpreter":{"hash":"0adcc2737ebf6a4a119f135174df96668767fca1ef1112612db5ecadf2b6d608"},"kernelspec":{"display_name":"Python 3.8.5 64-bit","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"}},"nbformat":4,"nbformat_minor":0}
